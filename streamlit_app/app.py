import streamlit as st
import requests
import json
from datetime import datetime

# --- Configuration ---
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "gemma:2b"

# --- System Prompt (V2 - Structured) ---
SYSTEM_PROMPT = """You are an AI Medical Assistant running locally.
Your goal is to provide preliminary triage advice.
1. Analyze the symptoms provided by the user.
2. Estimate urgency (Low, Medium, High, Emergency).
3. Suggest immediate actions (Home care vs Hospital).
4. Always advise seeing a doctor.
Keep responses concise and structured using Markdown."""

def query_ollama(prompt):
    """Envoie la requ√™te au mod√®le local Ollama."""
    full_prompt = f"{SYSTEM_PROMPT}\n\nUser Symptoms: {prompt}\nAssistant:"
    
    payload = {
        "model": MODEL_NAME,
        "prompt": full_prompt,
        "stream": False
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=payload)
        response.raise_for_status()
        return response.json()['response']
    except requests.exceptions.RequestException as e:
        return f"Error connecting to Ollama: {e}. Make sure Ollama is running (`ollama serve`)."

# --- Interface Streamlit ---
st.set_page_config(
    page_title="MedGemma Triage Prototype",
    page_icon="üè•",
    layout="centered"
)

# Header
st.title("üè• MedGemma Triage Assistant")
st.markdown("**Prototype Hackathon - Privacy-First AI Triage**")
st.markdown("---")

# Sidebar - Context & Privacy
with st.sidebar:
    st.header("‚ÑπÔ∏è √Ä propos")
    st.info(
        """
        Cette application utilise **Google Gemma (2B)** via Ollama pour analyser les sympt√¥mes.
        
        üîí **Privacy-First** : 
        Aucune donn√©e ne quitte votre ordinateur. Tout le traitement est local.
        """
    )
    st.warning(
        """
        **DISCLAIMER M√âDICAL**
        Ceci est une d√©monstration technique. 
        Ne pas utiliser pour de vraies urgences m√©dicales. 
        En cas d'urgence, appelez le 15 ou le 112.
        """
    )
    
    st.write(f"Mod√®le actif : `{MODEL_NAME}`")

# Main Input
st.subheader("Description des sympt√¥mes")
symptoms = st.text_area(
    "D√©crivez ce que vous ressentez (ex: 'Douleur poitrine bras gauche', 'Fi√®vre 39C enfant')...",
    height=150,
    placeholder="Ex: J'ai mal √† la t√™te et la lumi√®re me g√™ne..."
)

col1, col2 = st.columns([1, 4])
with col1:
    analyze_btn = st.button("üîç Analyser", type="primary")

# Analysis Logic
if analyze_btn:
    if not symptoms.strip():
        st.error("Veuillez entrer une description des sympt√¥mes.")
    else:
        with st.spinner("Analyse locale avec MedGemma en cours..."):
            # Simulation d'un petit d√©lai ou appel r√©el
            start_time = datetime.now()
            response = query_ollama(symptoms)
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
        # Display Results
        st.success(f"Analyse termin√©e en {duration:.2f} secondes.")
        
        st.markdown("### üìã Rapport de Triage")
        st.markdown("---")
        st.markdown(response)
        
        st.markdown("---")
        st.caption("G√©n√©r√© par MedGemma (Local Inference). V√©rifiez toujours avec un professionnel.")

# Footer
st.markdown("---")
st.markdown("*The MedGemma Impact Challenge - Prototype v0.1* ")
